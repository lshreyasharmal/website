{"ast":null,"code":"import comprehendit from'../assets/png/penguins_3.png';import langprep from'../assets/png/langprep.png';import smear from'../assets/png/smear.png';import mono from'../assets/png/mono.png';import five from\"../assets/svg/projects/five.svg\";import six from\"../assets/svg/projects/six.svg\";import seven from\"../assets/svg/projects/seven.svg\";import eight from\"../assets/svg/projects/eight.svg\";export const projectsData=[{id:1,projectName:'Comprehend.it',projectDesc:\"An education platform to transcribe videos or extract text from documents to generate quizzes, notes, and summaries from them using LLMs.\",tags:['Django','PyTorch','LangChain','Whisper','Llama-2','GPT-3.5'],code:'https://github.com/ML-AI-ProjectComprehend',demo:'https://drive.google.com/file/d/1wd8gZFlSjlFEgDaE6o0jfAE3jgGFzFQT/view',image:comprehendit},{id:2,projectName:'LangPrep',projectDesc:'An application to learn word pronunciation in diverse languages.',tags:['Django','AWS','S3','Textract','Polly'],code:'https://github.com/lshreyasharmal/langprep',demo:'https://www.youtube.com/watch?v=A9SPl5sjR88',image:langprep},{id:3,projectName:'SMeaR',projectDesc:'A GAN network to create a language agnostic embedding generator.',tags:['PyTorch','python','HuggingFace','GAN','BERT'],code:'https://github.com/lshreyasharmal',demo:'https://drive.google.com/file/d/1irzd7WUnMsKWctVo7bcwsvhLxLiSPtgX/view',image:smear},{id:4,projectName:'Unsupervised Monocular Depth Estimation from Video',projectDesc:'Enhanced depth estimation for monocular videos using self-attention and vision transformer, outperforming the baseline on KITT dataset. Implemented self-attention layers and ViT as image encoder with adversarial loss.',tags:['Flutter','Firebase'],code:'https://github.com/lshreyasharmal',demo:'https://drive.google.com/file/d/1Qg701VqlOVaMD0G9fIRvZBZqdx_B-3rC/view?usp=sharing',image:mono}];// Do not remove any fields.\n// Leave it blank instead as shown below\n/* \n{\n    id: 1,\n    projectName: 'Car Pooling System',\n    projectDesc: '',\n    tags: ['Flutter', 'React'],\n    code: '',\n    demo: '',\n    image: ''\n}, \n*/","map":{"version":3,"names":["comprehendit","langprep","smear","mono","five","six","seven","eight","projectsData","id","projectName","projectDesc","tags","code","demo","image"],"sources":["/Users/shreyasharma/Desktop/job search/website-main/lshreyasharmal.github.io/src/data/projectsData.js"],"sourcesContent":["import comprehendit from '../assets/png/penguins_3.png'\nimport langprep from '../assets/png/langprep.png'\nimport smear from '../assets/png/smear.png'\nimport mono from '../assets/png/mono.png'\nimport five from '../assets/svg/projects/five.svg'\nimport six from '../assets/svg/projects/six.svg'\nimport seven from '../assets/svg/projects/seven.svg'\nimport eight from '../assets/svg/projects/eight.svg'\n\n\nexport const projectsData = [\n    {\n        id: 1,\n        projectName: 'Comprehend.it',\n        projectDesc: \"An education platform to transcribe videos or extract text from documents to generate quizzes, notes, and summaries from them using LLMs.\",\n        tags: ['Django', 'PyTorch', 'LangChain', 'Whisper', 'Llama-2', 'GPT-3.5'],\n        code: 'https://github.com/ML-AI-ProjectComprehend',\n        demo: 'https://drive.google.com/file/d/1wd8gZFlSjlFEgDaE6o0jfAE3jgGFzFQT/view',\n        image: comprehendit\n    },\n    {\n        id: 2,\n        projectName: 'LangPrep',\n        projectDesc: 'An application to learn word pronunciation in diverse languages.',\n        tags: ['Django', 'AWS', 'S3', 'Textract', 'Polly'],\n        code: 'https://github.com/lshreyasharmal/langprep',\n        demo: 'https://www.youtube.com/watch?v=A9SPl5sjR88',\n        image: langprep\n    },\n    {\n        id: 3,\n        projectName: 'SMeaR',\n        projectDesc: 'A GAN network to create a language agnostic embedding generator.',\n        tags: ['PyTorch', 'python', 'HuggingFace', 'GAN', 'BERT'],\n        code: 'https://github.com/lshreyasharmal',\n        demo: 'https://drive.google.com/file/d/1irzd7WUnMsKWctVo7bcwsvhLxLiSPtgX/view',\n        image: smear\n    },\n    {\n        id: 4,\n        projectName: 'Unsupervised Monocular Depth Estimation from Video',\n        projectDesc: 'Enhanced depth estimation for monocular videos using self-attention and vision transformer, outperforming the baseline on KITT dataset. Implemented self-attention layers and ViT as image encoder with adversarial loss.',\n        tags: ['Flutter', 'Firebase'],\n        code: 'https://github.com/lshreyasharmal',\n        demo: 'https://drive.google.com/file/d/1Qg701VqlOVaMD0G9fIRvZBZqdx_B-3rC/view?usp=sharing',\n        image: mono\n    }\n]\n\n\n// Do not remove any fields.\n// Leave it blank instead as shown below\n\n/* \n{\n    id: 1,\n    projectName: 'Car Pooling System',\n    projectDesc: '',\n    tags: ['Flutter', 'React'],\n    code: '',\n    demo: '',\n    image: ''\n}, \n*/"],"mappings":"AAAA,MAAO,CAAAA,YAAY,KAAM,8BAA8B,CACvD,MAAO,CAAAC,QAAQ,KAAM,4BAA4B,CACjD,MAAO,CAAAC,KAAK,KAAM,yBAAyB,CAC3C,MAAO,CAAAC,IAAI,KAAM,wBAAwB,QAAAC,IAAA,8CAAAC,GAAA,6CAAAC,KAAA,+CAAAC,KAAA,wCAOzC,MAAO,MAAM,CAAAC,YAAY,CAAG,CACxB,CACIC,EAAE,CAAE,CAAC,CACLC,WAAW,CAAE,eAAe,CAC5BC,WAAW,CAAE,2IAA2I,CACxJC,IAAI,CAAE,CAAC,QAAQ,CAAE,SAAS,CAAE,WAAW,CAAE,SAAS,CAAE,SAAS,CAAE,SAAS,CAAC,CACzEC,IAAI,CAAE,4CAA4C,CAClDC,IAAI,CAAE,wEAAwE,CAC9EC,KAAK,CAAEf,YACX,CAAC,CACD,CACIS,EAAE,CAAE,CAAC,CACLC,WAAW,CAAE,UAAU,CACvBC,WAAW,CAAE,kEAAkE,CAC/EC,IAAI,CAAE,CAAC,QAAQ,CAAE,KAAK,CAAE,IAAI,CAAE,UAAU,CAAE,OAAO,CAAC,CAClDC,IAAI,CAAE,4CAA4C,CAClDC,IAAI,CAAE,6CAA6C,CACnDC,KAAK,CAAEd,QACX,CAAC,CACD,CACIQ,EAAE,CAAE,CAAC,CACLC,WAAW,CAAE,OAAO,CACpBC,WAAW,CAAE,kEAAkE,CAC/EC,IAAI,CAAE,CAAC,SAAS,CAAE,QAAQ,CAAE,aAAa,CAAE,KAAK,CAAE,MAAM,CAAC,CACzDC,IAAI,CAAE,mCAAmC,CACzCC,IAAI,CAAE,wEAAwE,CAC9EC,KAAK,CAAEb,KACX,CAAC,CACD,CACIO,EAAE,CAAE,CAAC,CACLC,WAAW,CAAE,oDAAoD,CACjEC,WAAW,CAAE,2NAA2N,CACxOC,IAAI,CAAE,CAAC,SAAS,CAAE,UAAU,CAAC,CAC7BC,IAAI,CAAE,mCAAmC,CACzCC,IAAI,CAAE,oFAAoF,CAC1FC,KAAK,CAAEZ,IACX,CAAC,CACJ,CAGD;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA"},"metadata":{},"sourceType":"module"}